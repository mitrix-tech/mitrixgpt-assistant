{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59e9ba8e-43ad-4d57-8b02-c456d4c371d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter API key for OpenAI:  ········\n",
      "Enter API key for LangSmith:  ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter API key for LangSmith: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14387411-09ff-4b63-8cad-5197940c23c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LANGSMITH_API_KEY in Settings > API Keys\n",
    "from langsmith import Client\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "client = Client()\n",
    "TASK = \"Guide on Mitrix Technology\" # Task to which prompt is related e.g. \"Writing jokes\"\n",
    "LAZY_PROMPT = \"\"\"You are an assistant at Mitrix Technology for question-answering tasks about the following\n",
    "aspects\n",
    "- overall info about the company\n",
    "- portfolio and use cases\n",
    "- services and expertise (including dev team background) \n",
    "- rough estimations for  and suggestion on tech stack\n",
    "- contacts\n",
    "\n",
    "to help leads know more about Mitrix Technology.\n",
    "\n",
    "Being an assistant at Mitrix Technology, always reffer to Mitrix as \"we\", \"us\", \"our\" etc., do not use e.g. 'they'.\n",
    "\n",
    "\n",
    ". Use the following pieces of retrieved context to answer the question. Provide as much facts as possible. \n",
    "\n",
    "If you don't know the answer based on the context or if the question is our of scope and not related to the Mitrix company, just say \"I don't know\" or something like \"I'm sorry, but I can't assist with that\". Use up to five sentences maximum and keep the answer concise.\n",
    "Question: {question} \n",
    "Context: {context} \n",
    "Answer:\"\"\" # Prompt to improve e.g. \"You are a world class standup comedian. Tell me a joke about the american people.\"\n",
    "REFINED_PROMPT_REPO_NAME = \"mitrixgpt-base\" # e.g. \"awesome-joke-generator\"\n",
    "REFINED_PROMPT_REPO_TAG = \"latest\"\n",
    "REFINED_PROMPT_REPO_IDENTIFIER = f\"{REFINED_PROMPT_REPO_NAME}:{REFINED_PROMPT_REPO_TAG}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1311fa5e-b4ae-4b0c-8e85-e61617e7e067",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "50c1f43c-fc49-476e-aa9f-8762ce982def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull the prompt maker\n",
    "prompt = client.pull_prompt(\"hardkothari/prompt-maker:latest\")\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d90b9e35-ea7b-41ae-956e-81b47fa7b3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = chain.invoke({\"task\": TASK, \"lazy_prompt\": LAZY_PROMPT})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f1bf989a-bf58-464f-bed8-81b716a7b280",
   "metadata": {},
   "outputs": [],
   "source": [
    "improved_template = messages \n",
    "# TODO: add some post-processing and params to construct a proper template\n",
    "# e.g. \"You are a world class comedian. tell me a joke about {topic}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3ae7e60-ffc2-42d5-8a0b-1821247e62d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As an expert assistant at Mitrix Technology, your role is to provide concise and informative answers to inquiries about our company. \\n\\n### Instructions:\\n- Always refer to Mitrix Technology as \"we,\" \"us,\" or \"our,\" avoiding third-person references like \"they.\"\\n- Address the following aspects in your responses:\\n  - Overall information about our company\\n  - Our portfolio and use cases\\n  - Our services and expertise, including the background of our development team\\n  - Rough estimations and suggestions regarding technology stacks\\n  - Contact information\\n\\nUtilize the provided context to formulate your answers, ensuring you include relevant facts. If the question falls outside the scope of Mitrix Technology or if you lack sufficient information, respond with \"I don\\'t know\" or \"I\\'m sorry, but I can\\'t assist with that.\" Keep your answers concise, limited to a maximum of five sentences.\\n\\n### Context:\\n{context} \\n\\n### Question:\\n{question} \\n\\n### Answer:'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "improved_template.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bca2bf-fbb7-417f-9fc8-1fb35abf2e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "improved_template.content = 'As an expert assistant at Mitrix Technology, your role is to provide concise and informative answers regarding key aspects of the company. \\n\\n### Instructions:\\n1. Deliver factual responses based on the specified categories:\\n   - Overview of Mitrix Technology\\n   - Service portfolio and relevant use cases\\n   - Areas of expertise, including the development team\\'s background\\n   - General estimations and recommendations for potential tech stacks\\n   - Contact information for inquiries\\n2. Keep responses to a maximum of five sentences, ensuring clarity and conciseness. Always reffer to Mitrix as \"we\", \"us\", do not use . \\n3. If the question falls outside the scope of the provided context or if you lack sufficient information, respond with \"I don\\'t know.\"\\n\\n### Context:\\n{context} \\n\\n### Question:\\n{question} \\n\\n### Answer:'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7ff6ab-27ef-4bd5-bf3e-cf8f3348efd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e875bd4a-ed43-41dc-8690-507b2f1058fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://smith.langchain.com/prompts/mitrixgpt-base/c53b4f0e?organizationId=3c038435-03d8-43a6-8900-3db067fee328'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "improved_prompt = ChatPromptTemplate.from_template(improved_template.content)\n",
    "refined_chain = improved_prompt | model\n",
    "\n",
    "client.push_prompt(REFINED_PROMPT_REPO_IDENTIFIER, object=refined_chain, is_public=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "121654e2-b41f-4a57-abc2-6d9bf20cba3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ListPromptsResponse(repos=[Prompt(repo_handle='mitrixgpt-base', description='', readme='', id='ddcfd583-9fe3-4ade-a28c-dfef45f10fcb', tenant_id='3c038435-03d8-43a6-8900-3db067fee328', created_at=datetime.datetime(2025, 3, 5, 12, 59, 1, 934813), updated_at=datetime.datetime(2025, 3, 7, 15, 35, 53, 760363), is_public=False, is_archived=False, tags=['ChatPromptTemplate'], original_repo_id=None, upstream_repo_id=None, owner=None, full_name='mitrixgpt-base', num_likes=0, num_downloads=110, num_views=10, liked_by_auth_user=False, last_commit_hash='c53b4f0eaf7f816b2e6365f23812b4f0a427c5c1a2e768093bb2ccfb1578760f', num_commits=5, original_repo_full_name=None, upstream_repo_full_name=None)], total=1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List my private prompts that include \"joke\"\n",
    "prompts = client.list_prompts(query=\"mitrix\", is_public=False)\n",
    "prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b6c22a-86da-4dc4-a7e1-9f18482951eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete a prompt\n",
    "# client.delete_prompt(PROMPT_REPO_NAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
